{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a4a6404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "305bbe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into cluster\n",
    "class Gaussian_Mixture_Model:\n",
    "    def __init__(self, n_components, max_iterations = 100, component_string = None):\n",
    "        self.n_components = n_components # number of clusters\n",
    "        self.max_iterations = max_iterations # maximum iterations algorithm uses\n",
    "        if component_string == None:\n",
    "            self.component_string = [f\"component{index}\" for index in \n",
    "                                    range(self.n_components)]\n",
    "        else:\n",
    "            self.component_string = component_string\n",
    "            # pi array for part of data in each cluster\n",
    "            self.pi = [1/self.n_components for component in range(self.n_components)]\n",
    "\n",
    "    # fit function so EM-algorithm runs; find mean vectors and covariance matrices\n",
    "    def fit(self, Y):\n",
    "        #split data into sub-sets based on n_components\n",
    "        Y_split = np.array_split(Y, self.n_components)\n",
    "        # initial covariance matrix and mean vector\n",
    "        self.covariance_matrices = [np.cov(y.T) for y in Y_split]\n",
    "        self.mean_vector = [np.mean(y, axis = 0) for y in Y_split]\n",
    "        #delete the split matrix, no longer needed for computations\n",
    "        del Y_split\n",
    "        \n",
    "    # fit function so EM-algorithm runs; find mean vectors and covariance matrices\n",
    "    def fit(self, Y):\n",
    "        #split data into sub-sets based on n_components\n",
    "        Y_split = np.array_split(Y, self.n_components)\n",
    "        # initial covariance matrix and mean vector\n",
    "        self.covariance_matrices = [np.cov(y.T) for y in Y_split]\n",
    "        self.mean_vector = [np.mean(y, axis = 0) for y in Y_split]\n",
    "        #delete the split matrix, no longer needed for computations\n",
    "        del Y_split\n",
    "        \n",
    "    for iteration in range(self.max_iterations): # E step\n",
    "    #probabilities for every cluster contained in every row\n",
    "    self.r = np.zeros(len(Y), self.n_components)\n",
    "    # calculate r matrix by doing the estimation part of the EM algorithm\n",
    "    for n in range(len(Y)):\n",
    "        for val in range(self.n_components):\n",
    "            self.r[n][val] = self.pi[val] * self.multivariate_normal(Y[n], self.mean_vector[val],\n",
    "                                                                     self.covariance_matrices[val])\n",
    "            self.r[n][val] /= sum([self.pi[col] * self.multivariate_normal(Y[n], self.mean_vector[col],\n",
    "                                                                          self.covariance_matrices[col]) for col in range(self.n_components)])\n",
    "            #calculate N list: sum of columns in r matrix\n",
    "            N = np.sum(self.r, axis = 0)\n",
    "    \n",
    "    def multivariate_normal(self, Y, mean_vector, covariance_matrix):\n",
    "        return (2*np.pi)**(-len(Y)/2) * np.linalg.det(covariance_matrix)**(-1/2) * np.exp(-np.dot(np.dot((Y-mean_vector).T,\n",
    "                                                                                                    np.linalg.inv(covariance_matrix)),\n",
    "                                                                                             (Y-mean_vector))/2)\n",
    "    # initialize mean vector; M step\n",
    "    self.mean_vector = np.zeros((self.n_components, len(Y[0])))\n",
    "    # for loop to update\n",
    "    for val in range(self.components):\n",
    "        for n in range(len(Y)):\n",
    "            self.mean_vector[val] += self.r[n][val] * Y[n]\n",
    "            self.mean_vector = [1/N[val] * self.mean_vector[val] for val in range(self.n_components)]\n",
    "    # list of covariance matrices\n",
    "    self.covariance_matrices = [np.zeros((len(Y[0])), len(Y[0])) for val in range(self.n_components)]\n",
    "    # for loop to update\n",
    "    for val in range(self.n_components):\n",
    "        self.covariance_matrices[val] = np.cov(Y.T, aweights = (self.r[:, val]), ddof = 0)\n",
    "        self.covariance_matrices = [1/N[val] * self.covariance_matrices[val] for val in range(self.n_components)]\n",
    "        # apply to pi list\n",
    "        self.pi = [N[val]/len(Y) for val in range(self.n_components)]\n",
    "    \n",
    "    \n",
    "    # GMM prediction function\n",
    "    def predict_GMM(self, Y):\n",
    "        probs = []\n",
    "        for n in range(len(Y)):\n",
    "            probs.append([self.multivariate_normal(Y[n], self.mean_vector[val], self.covariance_matrices[val])\n",
    "                          for k in range(self.n_components)])\n",
    "            cluster = []\n",
    "            for point in probs:\n",
    "                cluster.append(self.component_string[point.index(max(point))])\n",
    "                return cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31cb34e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
